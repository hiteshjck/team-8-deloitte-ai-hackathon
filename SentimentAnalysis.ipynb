{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis for Customer Reviews Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge:\n",
    "Develop a robust Sentiment Analysis classifier for XYZ customer reviews, automating the categorization into positive, negative, or neutral sentiments. Utilize Natural Language Processing (NLP) techniques, exploring different sentiment analysis methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "XYZ organization, a global online retail giant, accumulates a vast number of customer reviews daily. Extracting sentiments from these reviews offers insights into customer satisfaction, product quality, and market trends. The challenge is to create an effective sentiment analysis model that accurately classifies XYZ customer reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Instructions:\n",
    "\n",
    "1. Make sure this ipynb file that you have cloned is in the __Project__ folder on the Desktop. The Dataset is also available in the same folder.\n",
    "2. Ensure that all the cells in the notebook can be executed without any errors.\n",
    "3. Once the Challenge has been completed, save the SentimentAnalysis.ipynb notebook in the __*Project*__ Folder on the desktop. If the file is not present in that folder, autoevalution will fail.\n",
    "4. Print the evaluation metrics of the model. \n",
    "5. Before you submit the challenge for evaluation, please make sure you have assigned the Accuracy score of the model that was created for evaluation.\n",
    "6. Assign the Accuracy score obtained for the model created in this challenge to the specified variable in the predefined function *submit_accuracy_score*. The solution is to be written between the comments `# code starts here` and `# code ends here`\n",
    "7. Please do not make any changes to the variable names and the function name *submit_accuracy_score* as this will be used for automated evaluation of the challenge. Any modification in these names will result in unexpected behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------------------- CHALLENGE CODE STARTS HERE --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection\n",
    "# source 1 : Reviews.csv file provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...  \n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "# reading csv using pandas\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Reviews.csv')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  good quality dog food  i have bought several of the vitality canned d...  \n",
      "1      not as advertised  product arrived labeled as jumbo salted peanut...  \n",
      "2  \"delight\" says it all  this is a confection that has been around a fe...  \n",
      "3         cough medicine  if you are looking for the secret ingredient i...  \n",
      "4            great taffy  great taffy at a great price.  there was a wid...  \n",
      "Index([     0,      1,      2,      3,      4,      5,      6,      7,      8,\n",
      "            9,\n",
      "       ...\n",
      "       568444, 568445, 568446, 568447, 568448, 568449, 568450, 568451, 568452,\n",
      "       568453],\n",
      "      dtype='int64', length=568401)\n"
     ]
    }
   ],
   "source": [
    "# text cleaning\n",
    "# 1. removing leading and trailing spaces\n",
    "df[\"Summary\"] = df[\"Summary\"].str.strip()\n",
    "df[\"Text\"] = df[\"Text\"].str.strip()\n",
    "\n",
    "# 2. Removing special characters\n",
    "df[\"Summary\"] = df[\"Summary\"].str.replace(\"[\\\"$&+,:;=?@#|'<>.-^*()%!]\", \"\")\n",
    "df[\"Text\"] = df[\"Text\"].str.replace(\"[\\\"$&+,:;=?@#|'<>.-^*()%!]\", \"\")\n",
    "\n",
    "# tokenization\n",
    "#import nltk\n",
    "#df[\"tokenized summary\"] = df.apply(lambda row: nltk.word_tokenize(row[\"Summary\"]), axis=1)\n",
    "#df[\"tokenized text\"] = df.apply(lambda row: nltk.word_tokenize(row[\"Text\"]), axis=1)\n",
    "\n",
    "# Handling missing values\n",
    "# no missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Lowercasing\n",
    "df[\"Summary\"] = df[\"Summary\"].str.lower()\n",
    "df[\"Text\"] = df[\"Text\"].str.lower()\n",
    "\n",
    "print(df.head())\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8238315989479332\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.33      0.47     16452\n",
      "     neutral       0.63      0.01      0.01      8460\n",
      "    positive       0.82      0.99      0.90     88769\n",
      "\n",
      "    accuracy                           0.82    113681\n",
      "   macro avg       0.76      0.44      0.46    113681\n",
      "weighted avg       0.81      0.82      0.77    113681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sentiment analysis implementation\n",
    "# 1. Naive bayes algorithm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Map scores to sentiments (e.g., positive, neutral, negative)\n",
    "df['Sentiment'] = df['Score'].apply(lambda score: 'positive' if score > 3 else ('negative' if score < 3 else 'neutral'))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Create TF-IDF matrices for training and testing data\n",
    "X_train = vectorizer.fit_transform(train_data['Summary'])\n",
    "X_test = vectorizer.transform(test_data['Summary'])\n",
    "\n",
    "# Use a simple model (Naive Bayes) as a starting point\n",
    "model = make_pipeline(MultinomialNB())\n",
    "model.fit(X_train, train_data['Sentiment'])\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(test_data['Sentiment'], predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(test_data['Sentiment'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC()\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Summary'], \n",
    "                                df['Sentiment'], test_size=0.2, random_state=42)\n",
    "# Create TF-IDF matrices for training and testing data\n",
    "X_train = vectorizer.fit_transform(train_data['Summary'])\n",
    "X_test = vectorizer.transform(test_data['Summary'])\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate SVM\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------------------- CHALLENGE CODE ENDS HERE --------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE:\n",
    "1. Assign the Accuracy score obtained for the model created in this challenge to the specified variable in the predefined function *submit_accuracy_score* below. The solution is to be written between the comments `# code starts here` and `# code ends here`\n",
    "2. Please do not make any changes to the variable names and the function name *submit_accuracy_score* as this will be used for automated evaluation of the challenge. Any modification in these names will result in unexpected behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_accuracy_score()-> float:\n",
    "    #accuracy should be in the range of 0.0 to 1.0\n",
    "    accuracy = 0.0\n",
    "    # code starts here\n",
    "   \n",
    "    # code ends here\n",
    "    return accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
